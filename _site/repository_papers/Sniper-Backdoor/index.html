<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Sniper Backdoor: Single Client Targeted Backdoor Attack in Federated Learning</title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6">
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    
    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link href="../css/custom.css" rel="stylesheet">

  </head>

  <div class="container">
  <body>

    <center><span style="font-size:40px">
      Sniper Backdoor: Single Client Targeted Backdoor Attack in Federated Learning
    </span></center>
    <div class="gap-20"></div>

    <!---------------------  authors --------------------->
    <center>
    <span style="font-size:20px">
          &nbsp;
          <div style="display:inline-block">
          <a href="https://gorkaabad.github.io"><b>Gorka Abad</b></a>
          <sup style="font-size:15px">1</sup>
          <sup style="font-size:15px">2</sup>,
          </div>
          <div style="display:inline-block">
          <a href="https://hybridcores.com">Servio Paguada</a>
          <sup style="font-size:15px">1</sup>
          <sup style="font-size:15px">2</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://oguzhanersoy.github.io/">Oğuzhan Ersoy</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://www.ru.nl/en/people/picek-s">Stjepan Picek</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://scholar.google.es/citations?user=gpHy7UMAAAAJ&hl=es&oi=ao">Víctor Julio Ramírez-Durán</a>
          <sup style="font-size:15px">2</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://scholar.google.com/citations?user=OzKhvOEAAAAJ&hl=en">Aitor Urbieta</a>
          <sup style="font-size:15px">2</sup>
          </div>
    </span>
	</center>
    <!--------------------- affiliations --------------------->
    <div class="gap-5"></div>
    <div class="row">
      <div class="col-md-3"></div>
      <div class="col-md-3">
        <center><span style="font-size:20px">
          Radboud University<sup style="font-size:15px">1</sup>
        </span></center>
      </div>
      <div class="col-md-3">
        <center><span style="font-size:20px">
          Ikerlan Research Centre<sup style="font-size:15px">2</sup>
        </span></center>
      </div>
      <div class="col-md-3"></div>
    </div>
    <!-- <p>* Equal contribution</p> -->
    <hr>

    <!--------------------- links --------------------->
    <div class="gap-10"></div>

    <center>
    <span style="font-size:20px"> 
      <b>SaTML 2023</b>
      &nbsp; 
      [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136141">paper</a>]
      &nbsp;
      [<a href="bibtex.txt">BibTeX</a>]
      &nbsp; 
      [<a href="https://github.com/GorkaAbad/Sniper-Backdoor">code</a>]
    </span>
    <div class="gap-20"></div>

    </center>
<img width="100%" src="images/sniper.png">
<p></p>
<p><i>
  The overview of the attack: in 1) and 2), the FL is trained, and the attacker keeps a collection of submitted models.
  The attacker generated fake image samples in 3) and 4).
  In 5), the attacker trains a shadow network. In 6) and 7), the attacker identifies the victim using an SNN. 
  Lastly, in 8), the attacker injects the backdoor on the victim's model.
</i></p>
<hr>
    <!--------------------- abstract --------------------->
    <div class="gap-20"></div>
    <center><b><span style="font-size:25px">Abstract</span></b><br></center>
    <div class="gap-10"></div>
    <p> 
      Federated Learning (FL) enables collaborative training of Deep Learning (DL) models where the data is retained locally. Like DL, FL has severe security weaknesses that the attackers can exploit, e.g., model inversion and backdoor attacks. Model inversion attacks reconstruct the data from the training datasets, whereas backdoors misclassify only classes containing specific properties, e.g., a pixel pattern. Backdoors are prominent in FL and aim to poison every client model, while model inversion attacks can target even a single client.
    </p>
    <p>
      This paper introduces a novel technique to allow backdoor attacks to be client-targeted, compromising a single client while the rest remain unchanged. The attack takes advantage of state-of-the-art model inversion and backdoor attacks. Precisely, we leverage a Generative Adversarial Network to perform the model inversion. Afterward, we shadow-train the FL network, in which, using a Siamese Neural Network, we can identify, target, and backdoor the victim's model.
      Our attack has been validated using the MNIST, F-MNIST, EMNIST, and CIFAR-100 datasets under different settings---achieving up to 99% accuracy on both source (clean) and target (backdoor) classes and against state-of-the-art defenses, e.g., Neural Cleanse, opening a novel threat model to be considered in the future.
    </p>
  <hr>
  </body>
  </div>

  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="../js/bootstrap.min.js"></script>

</html>